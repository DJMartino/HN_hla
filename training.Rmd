---
title: "hla_analysis"
author: "David Martino"
date: "27 July 2015"
output: html_document
---
###preparation of data###

```{r load packages, include=FALSE}
Sys.setenv(http_proxy="http://proxy1.ap.webscanningservice.com:3128") 
library(reshape2)
library(plyr)
```

```{r read in data, include=FALSE}
rawdata=read.delim('HN2.hla.csv',header=T,sep=",",colClasses = c(Allele='character'))
imputes=read.delim('HN2.hla.txt',header=T,sep="")
phenotypes=read.delim('PEANUT_ALLERGY.4PLINK.phen',sep="",header=T)
phenotypes$Phenotype=ifelse(phenotypes$PEANUT_ALLERGY==2,'cases', 
             ifelse(phenotypes$PEANUT_ALLERGY==1,'controls', 'missing'))
```

```{r data summaries}
dat=merge(rawdata,phenotypes,by.x="IndividualID",by.y='IID')
dat=dat[!dat$Phenotype=='missing',]
dat$ANCESTRY=as.factor(as.character(dat$ANCESTRY))

table(dat$Phenotype,dat$ANCESTRY)
```

###Exploratory Analysis and Sanity Checks###

####Examine Allele Frequency Distributions####
Counts the number of cases and controls for each allele over each ancestral group
The input should be a data frame obtained by reading IMP1 or IMP2 imputation
calls, with an extra columns called "Phenotype" which takes two
possible values: "cases" and "controls", and "ANCESTRY" grouping variable

```{r initiate data structure with ancestry}
source('/Users/david/Documents/projects/healthnuts/hla/imputationData/imp2.v2/HN_hla/hlaAnalysis_ancestry.R')
counts=hlaCounts(dat,callThreshold=0.7)
```

####extract the haplotype counts####
```{r haplotype counts with ancestry}
hapCount=counts$haplotypeCounts

#Filter to remove alleles with low confidence calls (below threshold). 
foo=grep('NA',hapCount$Allele)
hapCount=hapCount[-foo,]

```

####check concordance beetween allele frequnecy cases versus controls####
```{r allelefreq cases v controls, fig.width=7, fig.height=7}
library(car)
z.cols <- cut(as.numeric(hapCount$ANCESTRY), 3, labels = c("red", "blue", "forest green"))
plot(hapCount$alleleFreq.cases,hapCount$alleleFreq.controls, cex=0.8,pch=19, xlab= 'allele frequency cases', ylab= 'allele frequency controls', main = 'Sanity Check', col = as.character(z.cols))
legend(0,0.8, unique(hapCount$ANCESTRY),pch=19, col = as.character(unique(z.cols)))
with(hapCount, dataEllipse(hapCount$alleleFreq.cases, hapCount$alleleFreq.controls, ANCESTRY, level=0.95, fill=TRUE, fill.alpha=0.1, plot.points=FALSE, add=TRUE,col=levels(z.cols), center.pch="+"))
coord=c(36, 230, 235, 242, 243, 284, 286, 332, 351)
with(hapCount[coord,],text(alleleFreq.cases,alleleFreq.controls,Allele, cex=0.8))
```


####Plot allele freq controls by ancestry####
```{r pop strat controls, fig.width=10, fig.height=10}
library(ggplot2)
ggplot(hapCount, aes(Allele, alleleFreq.controls, col=ANCESTRY)) + geom_point() + facet_wrap(~Gene, scale="free_y") + theme(axis.text.x=element_text(angle=45, hjust=1, size=5),legend.position="top")
```

###QC Stage###

#### Summaries and data structures to represent HLA allele data.####
Counts the number of cases and controls for each allele.
Creates a matrix representation which can be used for regression modelling.
```{r initiate data structure}
source('/Users/david/Documents/projects/healthnuts/hla/imputationData/imp2.v2/HN_hla/hlaAnalysis.R')
counts=hlaCounts(dat,callThreshold=0.7)
```

####extract the haplotype counts####
```{r haplotype counts}
hapCount=counts$haplotypeCounts

#Filter to remove alleles with low confidence calls (below threshold). 
foo=grep('NA',hapCount$Allele)
hapCount=hapCount[-foo,]
```


####QC filtering to remove alleles with less than 1% representation in the population####
```{r}
toremove=hapCount$alleleFreq.total<0.01
hapCount=hapCount[toremove=='FALSE',]

#Names of Alleles to analyse
alleles.hf=hapCount$Allele

# Names of all of the genes in the dataset.
genes <- sort(unique(dat$Gene))

# Combine gene and allele names.
dat$G.Allele <- paste(dat$Gene, dat$Allele, sep = ".")
```

####plot of hapCount freq in population####
```{r,fig.width=7, fig.height=7}
plot(as.factor(hapCount$Allele),hapCount$alleleFreq.cases, xaxt="n",main='Allele Frequency cases v controls')
with(hapCount,text(as.factor(Allele),alleleFreq.cases,Allele, cex=0.6,col='red'))
points(as.factor(hapCount$Allele),hapCount$alleleFreq.controls, xaxt="n")
with(hapCount,text(as.factor(Allele),alleleFreq.controls,Allele, cex=0.6,col='blue'))
```

####filter out low posterior calls####
```{r}
toremove=dat$Posterior<0.7
dat.2=dat[toremove==FALSE,]
```

####Compile model data set for statistics####
```{r}
dataMatrix <- dcast(melt(dat.2, measure.vars = "Posterior"),
                       IndividualID + ANCESTRY +GENDER + Phenotype ~ G.Allele,
                       length)
```

####Filter out low frequency alleles####
```{r}
df=as.data.frame(dataMatrix[,-(1:4)])
foo=colnames(df)%in%alleles.hf
keep=df[,which(colnames(df)%in%alleles.hf)]
modelData=cbind(dataMatrix[,c(1:4)],keep)
```

####Regression analysis####
```{r, logistic regression}
#Define response
pheno=ifelse(modelData$Phenotype == 'controls', 0,1)

fit.glm0 <-  glm(pheno~0,data = modelData, family='binomial')
fit.glm1 <-  glm(pheno~ANCESTRY+GENDER,data = modelData, family='binomial')
fit.glm2 <-  glm(pheno~ANCESTRY+GENDER+DQA1.0102, data = modelData, family='binomial')
fit.glm3 <-  glm(pheno~ANCESTRY+GENDER+DRB1.1501, data = modelData, family='binomial')
fit.glm4 <-  glm(pheno~ANCESTRY+GENDER+DQB1.0604, data = modelData, family='binomial')

anova(fit.glm0,fit.glm1,fit.glm2,fit.glm3,fit.glm4,test="LRT")
```

####Model vis####
```{r, DQA1.0102 visualise the model fit,fig.width=7, fig.height=7}
library(visreg)
par(mfrow=c(2,3))
visreg(fit.glm2, ylab = "log odds (Food Allergy)")
```

####Statistics####
```{r, for DQA1.0102 extract the odds ratios and statistics}
# OR estimate 
m.fit.or <- exp(coef(summary(fit.glm2))[, 1])

# p-val and se estimate
m.fit.p <- coef(summary(fit.glm2))[, c(2,4)]

#combine them
m.fit=cbind(m.fit.or,m.fit.p)
colnames(m.fit) <- c("OR", "se.OR", "p.wald")

# 95% CI for the OR.
ci <- exp(confint.default(fit.glm2))

#package up
table=cbind(m.fit,ci)

#print to screen
table
```

####Stratified analysis####
```{r, for DQA1.0102 stratified analysis}
glm2.strat <-  glm(pheno~GENDER+DQA1.0102*ANCESTRY, data = modelData, family='binomial')
visreg(glm2.strat, "DQA1.0102", by = "ANCESTRY",ylab = "log odds (Food Allergy)")
```

```{r, statistics for stratified analysis DQA1}
glm.AS <-  glm(pheno~GENDER+DQA1.0102, data = modelData, family='binomial', subset=ANCESTRY=='Asian')
glm.EU <-  glm(pheno~GENDER+DQA1.0102, data = modelData, family='binomial', subset=ANCESTRY=='European')
glm.EA <-  glm(pheno~GENDER+DQA1.0102, data = modelData, family='binomial', subset=ANCESTRY=='MixedEuropeanAsian')

# OR estimate 
m.fit.AS <- exp(coef(summary(glm.AS))[, 1])
m.fit.EU <- exp(coef(summary(glm.EU))[, 1])
m.fit.EA <- exp(coef(summary(glm.EA))[, 1])

# p-val and se estimate
m.fit.pAS <- coef(summary(glm.AS))[, c(2,4)]
m.fit.pEU <- coef(summary(glm.EU))[, c(2,4)]
m.fit.pEA <- coef(summary(glm.EA))[, c(2,4)]

# 95% CI for the OR.
ci.AS <- exp(confint.default(glm.AS))
ci.EU <- exp(confint.default(glm.EU))
ci.EA <- exp(confint.default(glm.EA))

#combine them
stat.fit.AS=cbind(m.fit.AS,m.fit.pAS,ci.AS)
colnames(stat.fit.AS) <- c("OR", "se.OR", "p.wald","2.5%","97.5%")
stat.fit.EU=cbind(m.fit.EU,m.fit.pEU,ci.EU)
colnames(stat.fit.EU) <- c("OR", "se.OR", "p.wald","2.5%","97.5%")
stat.fit.EA=cbind(m.fit.EA,m.fit.pEU,ci.EA)
colnames(stat.fit.EA) <- c("OR", "se.OR", "p.wald","2.5%","97.5%")

#package up
table=list(Asian=stat.fit.AS,European=stat.fit.EU,Admixed=stat.fit.EA)

#print to screen
table
```

####Model vis####
```{r, DRB1.1501 visualise the model fit,fig.width=7, fig.height=7}
library(visreg)
par(mfrow=c(2,3))
visreg(fit.glm3, ylab = "log odds (Food Allergy)")
```

####Statistics####
```{r, for DRB1.1501 extract the odds ratios and statistics}
# OR estimate 
m.fit.or <- exp(coef(summary(fit.glm3))[, 1])

# p-val and se estimate
m.fit.p <- coef(summary(fit.glm3))[, c(2,4)]

#combine them
m.fit=cbind(m.fit.or,m.fit.p)
colnames(m.fit) <- c("OR", "se.OR", "p.wald")

# 95% CI for the OR.
ci <- exp(confint.default(fit.glm3))

#package up
table=cbind(m.fit,ci)

#print to screen
table
```

####Stratified analysis####
```{r, for DRB1.1501 stratified analysis}
glm3.strat <-  glm(pheno~GENDER+DRB1.1501*ANCESTRY, data = modelData, family='binomial')
visreg(glm3.strat, "DRB1.1501", by = "ANCESTRY",ylab = "log odds (Food Allergy)")
```

```{r, statistics for stratified analysis DRB1}
glm.AS <-  glm(pheno~GENDER+DRB1.1501, data = modelData, family='binomial', subset=ANCESTRY=='Asian')
glm.EU <-  glm(pheno~GENDER+DRB1.1501, data = modelData, family='binomial', subset=ANCESTRY=='European')
glm.EA <-  glm(pheno~GENDER+DRB1.1501, data = modelData, family='binomial', subset=ANCESTRY=='MixedEuropeanAsian')

# OR estimate 
m.fit.AS <- exp(coef(summary(glm.AS))[, 1])
m.fit.EU <- exp(coef(summary(glm.EU))[, 1])
m.fit.EA <- exp(coef(summary(glm.EA))[, 1])

# p-val and se estimate
m.fit.pAS <- coef(summary(glm.AS))[, c(2,4)]
m.fit.pEU <- coef(summary(glm.EU))[, c(2,4)]
m.fit.pEA <- coef(summary(glm.EA))[, c(2,4)]

# 95% CI for the OR.
ci.AS <- exp(confint.default(glm.AS))
ci.EU <- exp(confint.default(glm.EU))
ci.EA <- exp(confint.default(glm.EA))

#combine them
stat.fit.AS=cbind(m.fit.AS,m.fit.pAS,ci.AS)
colnames(stat.fit.AS) <- c("OR", "se.OR", "p.wald","2.5%","97.5%")
stat.fit.EU=cbind(m.fit.EU,m.fit.pEU,ci.EU)
colnames(stat.fit.EU) <- c("OR", "se.OR", "p.wald","2.5%","97.5%")
stat.fit.EA=cbind(m.fit.EA,m.fit.pEU,ci.EA)
colnames(stat.fit.EA) <- c("OR", "se.OR", "p.wald","2.5%","97.5%")

#package up
table=list(Asian=stat.fit.AS,European=stat.fit.EU,Admixed=stat.fit.EA)

#print to screen
table
```

###Haplotype level analysis###  ???Am i filtering here? Use dat.2 or dat
####initiate a haplo stats matrix####
```{r initiate haplo.stats matrix}
library(haplo.stats)

rd=dcast(dat, IndividualID + GENDER + ANCESTRY + Phenotype ~ Gene + Chromosome, value.var = "Allele")
colnames(rd)[5:20]= gsub("_", ".a",colnames(rd)[5:20])
head(rd)
```

###Global haplotype score sliding###
Identify subhaplotypes from a group of loci using association testing under an additive model
Consider a 'window' of 2 genes
P-value estimates by permutation adjusted for gender and ethnicity
Consider only haplotypes with an obverved pop frequency > 0.01
```{r}
#Recode phenotype
y.bin <- 1*(rd$Phenotype=="cases")

#matrix of confounding variables
x.ma <- cbind(rd$ANCESTRY, rd$GENDER)

genotypes=rd[,-c(1:4)]
rownames(genotypes)=rd$IndividualID

#re-order columns according to agree with chromosomal location
genotypes=genotypes[,c(1,2,5,6,3,4,15,16,11,12,13,14,7,8,9,10)]

label=c("A","C","B","DRB1","DQA1","DQB1","DPA1","DPB1")

score.slide.bin <- haplo.score.slide(y.bin, genotypes, trait.type="binomial",
  x.adj = x.ma, skip.haplo = 0.01,haplo.effect="additive",miss.val=0,
  locus.label=label,simulate=TRUE,
  sim.control=score.sim.control(min.sim=200,max.sim=500,verbose=F))
 
plot.haplo.score.slide(score.slide.bin)
```

####filter to class II genes DRB1 and DQB1 combinations####
```{r subset data}
genotypes=genotypes[,c(7:10)]
rownames(genotypes)=rd$IndividualID
classII=as.character(label[c(4,5)])
head(genotypes)
```

###QC Removal of missing alleles###
####Compute the number of loci with 0,1 or 2 missing alleles and count the number of potential haplotype pairs that are consistent with the observed data. Remove missingness.####
```{r,include=FALSE}
###Preview missing data###
geno.desc <- summaryGeno(genotypes, miss.val=c(0,NA))

#Sum of missing alleles per individual
miss.all <- which(geno.desc[,4] > 100000)
geno.updated <- genotypes[-miss.all,]
```

###Haplotype frequency estimation###
computes maximum likelihood estimates of haplotype probabilities. Posterior probabilities of haplotype pairs for each subject are also computed.Haplotype probabilities by group are also computed.
```{r compute haplotype probs}
seed <- c(17, 53, 1, 40, 37, 0, 62, 56, 5, 52, 12, 1)
set.seed(seed)

save.em <- haplo.em(geno=genotypes, locus.label=classII, miss.val=c(NA),
  control = haplo.em.control(n.try = 40, insert.batch.size=2))

print(save.em,nlines=20)
summary(save.em,show.haplo=TRUE,nlines=20)
```

####Compute haplotype frequencies according to each level of grouping variable.#####
```{r compute group frequencies}
group.bin <- haplo.group(y.bin, genotypes, locus.label=as.character(classII), miss.val=0)
print(group.bin, nlines=10)
```

###test assocaition between haplotypes and phenotype using EM method of Schaid et al###

Hapltype effects modelled as 'additive' adjusting for gender and ancestry
p-values computed by permutation of traits and covariates.
Computes the maximum likelihood estimates of the haplotype frequencies and the posterior probabilities of the pairs of haplotypes for each subject using an EM algorithm. The algorithm begins with haplotypes from a subset of the loci and progressively discards those with low frequency before inserting more loci. The process is repeated until haplotypes for all loci are established. The posterior probabilities are used to compute the score statistics for the association of (ambiguous) haplotypes with traits. 

```{r initiate EM algorithm}
x.ma <- cbind(rd$ANCESTRY, rd$GENDER)

score.bin <- haplo.score(y.bin, genotypes, trait.type="binomial",
  x.adj = x.ma, skip.haplo = 0.01,haplo.effect="additive",miss.val=0,
  locus.label=as.character(classII),simulate=TRUE,
  sim.control=score.sim.control(min.sim=200,max.sim=500,verbose=F))

print.haplo.score(score.bin)
```

####merge stats with haplo freq by group####
```{r merge stats with freqs}
merge.bin <- haplo.score.merge(score.bin, group.bin)
print.haplo.score.merge(merge.bin,order.by="p.val")
```


###Binomial regression models###
```{r binomial regression, warning=FALSE}
geno.glm <- setupGeno(genotypes, miss.val=c(0,NA), locus.label=classII)
glm.data <- data.frame(geno.glm, ancestry=rd$ANCESTRY, gender=rd$GENDER, y.bin=y.bin)

fit.bin <- haplo.glm(y.bin ~ ancestry + gender + geno.glm, family = binomial,
                     data=glm.data, na.action = "na.exclude",
                     locus.label=classII,
                     control = haplo.glm.control(haplo.effect='additive',haplo.freq.min = .01,haplo.base= 6))

summary(fit.bin)

fit.bin0<- glm(y.bin ~ ancestry + gender, family = binomial, data=glm.data)
anova.haplo.glm(fit.bin0, fit.bin)
```

####filter to class II genes DPA1 and DPB1 combinations####
```{r subset data 2}
genotypes=rd[,-c(1:4)]
rownames(genotypes)=rd$IndividualID
genotypes=genotypes[,c(1,2,5,6,3,4,15,16,11,12,13,14,7,8,9,10)]
genotypes=genotypes[,c(13:16)]
rownames(genotypes)=rd$IndividualID
classII=as.character(label[c(7,8)])
head(genotypes)
```

###Haplotype frequency estimation###
computes maximum likelihood estimates of haplotype probabilities. Posterior probabilities of haplotype pairs for each subject are also computed.Haplotype probabilities by group are also computed.
```{r compute haplotype probs 2}
seed <- c(17, 53, 1, 40, 37, 0, 62, 56, 5, 52, 12, 1)
set.seed(seed)

save.em <- haplo.em(geno=genotypes, locus.label=classII, miss.val=c(NA),
  control = haplo.em.control(n.try = 40, insert.batch.size=2))

print(save.em,nlines=20)
summary(save.em,show.haplo=TRUE,nlines=20)
```

####Compute haplotype frequencies according to each level of grouping variable.#####
```{r compute group frequencies 2}
group.bin <- haplo.group(y.bin, genotypes, locus.label=as.character(classII), miss.val=0)
print(group.bin, nlines=10)
```

###test assocaition between haplotypes and phenotype using EM method of Schaid et al###

Hapltype effects modelled as 'additive' adjusting for gender and ancestry
p-values computed by permutation of traits and covariates.
Computes the maximum likelihood estimates of the haplotype frequencies and the posterior probabilities of the pairs of haplotypes for each subject using an EM algorithm. The algorithm begins with haplotypes from a subset of the loci and progressively discards those with low frequency before inserting more loci. The process is repeated until haplotypes for all loci are established. The posterior probabilities are used to compute the score statistics for the association of (ambiguous) haplotypes with traits. 

```{r initiate EM algorithm 2}
x.ma <- cbind(rd$ANCESTRY, rd$GENDER)

score.bin <- haplo.score(y.bin, genotypes, trait.type="binomial",
  x.adj = x.ma, skip.haplo = 0.01,haplo.effect="additive",miss.val=0,
  locus.label=as.character(classII),simulate=TRUE,
  sim.control=score.sim.control(min.sim=200,max.sim=500,verbose=F))

print.haplo.score(score.bin)
```

####merge stats with haplo freq by group####
```{r merge stats with freqs 2}
merge.bin <- haplo.score.merge(score.bin, group.bin)
print.haplo.score.merge(merge.bin,order.by="p.val")
```

###Binomial regression models###
```{r binomial regression 2, warning=FALSE}
geno.glm <- setupGeno(genotypes, miss.val=c(0,NA), locus.label=classII)
glm.data <- data.frame(geno.glm, ancestry=rd$ANCESTRY, gender=rd$GENDER, y.bin=y.bin)

fit.bin <- haplo.glm(y.bin ~ ancestry + gender + geno.glm, family = binomial,
                     data=glm.data, na.action = "na.exclude",
                     locus.label=classII,
                     control = haplo.glm.control(haplo.effect='additive',haplo.freq.min = .01,haplo.base= 6))

summary(fit.bin)

fit.bin0<- glm(y.bin ~ ancestry + gender, family = binomial, data=glm.data)
anova.haplo.glm(fit.bin0, fit.bin)
```



